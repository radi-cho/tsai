{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.GatedTabTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GatedTabTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation is based on:\n",
    "\n",
    "- Cholakov, R., & Kolev, T. (2022). ***The GatedTabTransformer. An enhanced deep learning architecture for tabular modeling. arXiv preprint arXiv:2201.00199***. arXiv preprint https://arxiv.org/abs/2201.00199\n",
    "- Huang, X., Khetan, A., Cvitkovic, M., & Karnin, Z. (2020). ***TabTransformer: Tabular Data Modeling Using Contextual Embeddings***. arXiv preprint https://arxiv.org/pdf/2012.06678\n",
    "\n",
    "Official repo: https://github.com/radi-cho/GatedTabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from tsai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tsai.models.TabTransformer import TabTransformer\n",
    "from tsai.models.gMLP import gMLPClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _TabMLP(nn.Module):\n",
    "    def __init__(self, classes, cont_names, c_out, d_model, mlp_d_model, mlp_d_ffn, mlp_layers):\n",
    "        super().__init__()\n",
    "        seq_len = d_model * len(classes) + len(cont_names)\n",
    "        self.mlp = gMLPClassification(1, c_out, seq_len, d_model=mlp_d_model, d_ffn=mlp_d_ffn, depth=mlp_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "class GatedTabTransformer(TabTransformer):\n",
    "    def __init__(self, classes, cont_names, c_out, column_embed=True, add_shared_embed=False, shared_embed_div=8, embed_dropout=0.1, drop_whole_embed=False, \n",
    "                 d_model=32, n_layers=6, n_heads=8, d_k=None, d_v=None, d_ff=None, res_attention=True, attention_act='gelu', res_dropout=0.1, norm_cont=True,\n",
    "                 mlp_d_model=32, mlp_d_ffn=64, mlp_layers=4):\n",
    "\n",
    "        super().__init__(classes, cont_names, c_out, column_embed=column_embed, add_shared_embed=add_shared_embed, shared_embed_div=shared_embed_div,\n",
    "                         embed_dropout=embed_dropout, drop_whole_embed=drop_whole_embed, d_model=d_model, n_layers=n_layers, n_heads=n_heads, d_k=d_k,\n",
    "                         d_v=d_v, d_ff=d_ff, res_attention=res_attention, attention_act=attention_act, res_dropout=res_dropout, norm_cont=norm_cont)\n",
    "\n",
    "        self.mlp = _TabMLP(classes, cont_names, c_out, d_model, mlp_d_model, mlp_d_ffn, mlp_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_eq\n",
    "from fastcore.basics import first\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastai.tabular.data import TabularDataLoaders\n",
    "from fastai.tabular.core import Categorify, FillMissing\n",
    "from fastai.data.transforms import Normalize\n",
    "import pandas as pd\n",
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')\n",
    "dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n",
    "    cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n",
    "    cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "    procs = [Categorify, FillMissing, Normalize])\n",
    "x_cat, x_cont, yb = first(dls.train)\n",
    "model = GatedTabTransformer(dls.classes, dls.cont_names, dls.c)\n",
    "test_eq(model(x_cat, x_cont).shape, (dls.train.bs, dls.c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from tsai.imports import create_scripts\n",
    "from tsai.export import get_nb_name\n",
    "nb_name = get_nb_name()\n",
    "create_scripts(nb_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
