---

title: RNN_FCNPlus


keywords: fastai
sidebar: home_sidebar

summary: "This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@gmail.com based on:"
description: "This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@gmail.com based on:"
nb_path: "nbs/107b_models.RNN_FCNPlus.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/107b_models.RNN_FCNPlus.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="RNN_FCNPlus" class="doc_header"><code>class</code> <code>RNN_FCNPlus</code><a href="https://github.com/timeseriesAI/tsai/tree/main/tsai/models/RNN_FCNPlus.py#L76" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>RNN_FCNPlus</code>(<strong><code>c_in</code></strong>, <strong><code>c_out</code></strong>, <strong><code>seq_len</code></strong>=<em><code>None</code></em>, <strong><code>hidden_size</code></strong>=<em><code>100</code></em>, <strong><code>rnn_layers</code></strong>=<em><code>1</code></em>, <strong><code>bias</code></strong>=<em><code>True</code></em>, <strong><code>cell_dropout</code></strong>=<em><code>0</code></em>, <strong><code>rnn_dropout</code></strong>=<em><code>0.8</code></em>, <strong><code>bidirectional</code></strong>=<em><code>False</code></em>, <strong><code>shuffle</code></strong>=<em><code>True</code></em>, <strong><code>fc_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>conv_layers</code></strong>=<em><code>[128, 256, 128]</code></em>, <strong><code>kss</code></strong>=<em><code>[7, 5, 3]</code></em>, <strong><code>se</code></strong>=<em><code>0</code></em>, <strong><code>custom_head</code></strong>=<em><code>None</code></em>) :: <code>_RNN_FCN_BasePlus</code></p>
</blockquote>
<p>A sequential container.
Modules will be added to it in the order they are passed in the
constructor. Alternatively, an <code>OrderedDict</code> of modules can be
passed in. The <code>forward()</code> method of <code>Sequential</code> accepts any
input and forwards it to the first module it contains. It then
"chains" outputs to inputs sequentially for each subsequent module,
finally returning the output of the last module.</p>
<p>The value a <code>Sequential</code> provides over manually calling a sequence
of modules is that it allows treating the whole container as a
single module, such that performing a transformation on the
<code>Sequential</code> applies to each of the modules it stores (which are
each a registered submodule of the <code>Sequential</code>).</p>
<p>What's the difference between a <code>Sequential</code> and a
:class:<code>torch.nn.ModuleList</code>? A <code>ModuleList</code> is exactly what it
sounds like--a list for storing <code>Module</code> s! On the other hand,
the layers in a <code>Sequential</code> are connected in a cascading way.</p>
<p>Example::</p>

<pre><code># Using Sequential to create a small model. When `model` is run,
# input will first be passed to `Conv2d(1,20,5)`. The output of
# `Conv2d(1,20,5)` will be used as the input to the first
# `ReLU`; the output of the first `ReLU` will become the input
# for `Conv2d(20,64,5)`. Finally, the output of
# `Conv2d(20,64,5)` will be used as input to the second `ReLU`
model = nn.Sequential(
          nn.Conv2d(1,20,5),
          nn.ReLU(),
          nn.Conv2d(20,64,5),
          nn.ReLU()
        )

# Using Sequential with OrderedDict. This is functionally the
# same as the above code
model = nn.Sequential(OrderedDict([
          ('conv1', nn.Conv2d(1,20,5)),
          ('relu1', nn.ReLU()),
          ('conv2', nn.Conv2d(20,64,5)),
          ('relu2', nn.ReLU())
        ]))</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LSTM_FCNPlus" class="doc_header"><code>class</code> <code>LSTM_FCNPlus</code><a href="https://github.com/timeseriesAI/tsai/tree/main/tsai/models/RNN_FCNPlus.py#L79" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LSTM_FCNPlus</code>(<strong><code>c_in</code></strong>, <strong><code>c_out</code></strong>, <strong><code>seq_len</code></strong>=<em><code>None</code></em>, <strong><code>hidden_size</code></strong>=<em><code>100</code></em>, <strong><code>rnn_layers</code></strong>=<em><code>1</code></em>, <strong><code>bias</code></strong>=<em><code>True</code></em>, <strong><code>cell_dropout</code></strong>=<em><code>0</code></em>, <strong><code>rnn_dropout</code></strong>=<em><code>0.8</code></em>, <strong><code>bidirectional</code></strong>=<em><code>False</code></em>, <strong><code>shuffle</code></strong>=<em><code>True</code></em>, <strong><code>fc_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>conv_layers</code></strong>=<em><code>[128, 256, 128]</code></em>, <strong><code>kss</code></strong>=<em><code>[7, 5, 3]</code></em>, <strong><code>se</code></strong>=<em><code>0</code></em>, <strong><code>custom_head</code></strong>=<em><code>None</code></em>) :: <code>_RNN_FCN_BasePlus</code></p>
</blockquote>
<p>A sequential container.
Modules will be added to it in the order they are passed in the
constructor. Alternatively, an <code>OrderedDict</code> of modules can be
passed in. The <code>forward()</code> method of <code>Sequential</code> accepts any
input and forwards it to the first module it contains. It then
"chains" outputs to inputs sequentially for each subsequent module,
finally returning the output of the last module.</p>
<p>The value a <code>Sequential</code> provides over manually calling a sequence
of modules is that it allows treating the whole container as a
single module, such that performing a transformation on the
<code>Sequential</code> applies to each of the modules it stores (which are
each a registered submodule of the <code>Sequential</code>).</p>
<p>What's the difference between a <code>Sequential</code> and a
:class:<code>torch.nn.ModuleList</code>? A <code>ModuleList</code> is exactly what it
sounds like--a list for storing <code>Module</code> s! On the other hand,
the layers in a <code>Sequential</code> are connected in a cascading way.</p>
<p>Example::</p>

<pre><code># Using Sequential to create a small model. When `model` is run,
# input will first be passed to `Conv2d(1,20,5)`. The output of
# `Conv2d(1,20,5)` will be used as the input to the first
# `ReLU`; the output of the first `ReLU` will become the input
# for `Conv2d(20,64,5)`. Finally, the output of
# `Conv2d(20,64,5)` will be used as input to the second `ReLU`
model = nn.Sequential(
          nn.Conv2d(1,20,5),
          nn.ReLU(),
          nn.Conv2d(20,64,5),
          nn.ReLU()
        )

# Using Sequential with OrderedDict. This is functionally the
# same as the above code
model = nn.Sequential(OrderedDict([
          ('conv1', nn.Conv2d(1,20,5)),
          ('relu1', nn.ReLU()),
          ('conv2', nn.Conv2d(20,64,5)),
          ('relu2', nn.ReLU())
        ]))</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GRU_FCNPlus" class="doc_header"><code>class</code> <code>GRU_FCNPlus</code><a href="https://github.com/timeseriesAI/tsai/tree/main/tsai/models/RNN_FCNPlus.py#L82" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>GRU_FCNPlus</code>(<strong><code>c_in</code></strong>, <strong><code>c_out</code></strong>, <strong><code>seq_len</code></strong>=<em><code>None</code></em>, <strong><code>hidden_size</code></strong>=<em><code>100</code></em>, <strong><code>rnn_layers</code></strong>=<em><code>1</code></em>, <strong><code>bias</code></strong>=<em><code>True</code></em>, <strong><code>cell_dropout</code></strong>=<em><code>0</code></em>, <strong><code>rnn_dropout</code></strong>=<em><code>0.8</code></em>, <strong><code>bidirectional</code></strong>=<em><code>False</code></em>, <strong><code>shuffle</code></strong>=<em><code>True</code></em>, <strong><code>fc_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>conv_layers</code></strong>=<em><code>[128, 256, 128]</code></em>, <strong><code>kss</code></strong>=<em><code>[7, 5, 3]</code></em>, <strong><code>se</code></strong>=<em><code>0</code></em>, <strong><code>custom_head</code></strong>=<em><code>None</code></em>) :: <code>_RNN_FCN_BasePlus</code></p>
</blockquote>
<p>A sequential container.
Modules will be added to it in the order they are passed in the
constructor. Alternatively, an <code>OrderedDict</code> of modules can be
passed in. The <code>forward()</code> method of <code>Sequential</code> accepts any
input and forwards it to the first module it contains. It then
"chains" outputs to inputs sequentially for each subsequent module,
finally returning the output of the last module.</p>
<p>The value a <code>Sequential</code> provides over manually calling a sequence
of modules is that it allows treating the whole container as a
single module, such that performing a transformation on the
<code>Sequential</code> applies to each of the modules it stores (which are
each a registered submodule of the <code>Sequential</code>).</p>
<p>What's the difference between a <code>Sequential</code> and a
:class:<code>torch.nn.ModuleList</code>? A <code>ModuleList</code> is exactly what it
sounds like--a list for storing <code>Module</code> s! On the other hand,
the layers in a <code>Sequential</code> are connected in a cascading way.</p>
<p>Example::</p>

<pre><code># Using Sequential to create a small model. When `model` is run,
# input will first be passed to `Conv2d(1,20,5)`. The output of
# `Conv2d(1,20,5)` will be used as the input to the first
# `ReLU`; the output of the first `ReLU` will become the input
# for `Conv2d(20,64,5)`. Finally, the output of
# `Conv2d(20,64,5)` will be used as input to the second `ReLU`
model = nn.Sequential(
          nn.Conv2d(1,20,5),
          nn.ReLU(),
          nn.Conv2d(20,64,5),
          nn.ReLU()
        )

# Using Sequential with OrderedDict. This is functionally the
# same as the above code
model = nn.Sequential(OrderedDict([
          ('conv1', nn.Conv2d(1,20,5)),
          ('relu1', nn.ReLU()),
          ('conv2', nn.Conv2d(20,64,5)),
          ('relu2', nn.ReLU())
        ]))</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MRNN_FCNPlus" class="doc_header"><code>class</code> <code>MRNN_FCNPlus</code><a href="https://github.com/timeseriesAI/tsai/tree/main/tsai/models/RNN_FCNPlus.py#L85" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MRNN_FCNPlus</code>(<strong>*<code>args</code></strong>, <strong><code>se</code></strong>=<em><code>16</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>_RNN_FCN_BasePlus</code></p>
</blockquote>
<p>A sequential container.
Modules will be added to it in the order they are passed in the
constructor. Alternatively, an <code>OrderedDict</code> of modules can be
passed in. The <code>forward()</code> method of <code>Sequential</code> accepts any
input and forwards it to the first module it contains. It then
"chains" outputs to inputs sequentially for each subsequent module,
finally returning the output of the last module.</p>
<p>The value a <code>Sequential</code> provides over manually calling a sequence
of modules is that it allows treating the whole container as a
single module, such that performing a transformation on the
<code>Sequential</code> applies to each of the modules it stores (which are
each a registered submodule of the <code>Sequential</code>).</p>
<p>What's the difference between a <code>Sequential</code> and a
:class:<code>torch.nn.ModuleList</code>? A <code>ModuleList</code> is exactly what it
sounds like--a list for storing <code>Module</code> s! On the other hand,
the layers in a <code>Sequential</code> are connected in a cascading way.</p>
<p>Example::</p>

<pre><code># Using Sequential to create a small model. When `model` is run,
# input will first be passed to `Conv2d(1,20,5)`. The output of
# `Conv2d(1,20,5)` will be used as the input to the first
# `ReLU`; the output of the first `ReLU` will become the input
# for `Conv2d(20,64,5)`. Finally, the output of
# `Conv2d(20,64,5)` will be used as input to the second `ReLU`
model = nn.Sequential(
          nn.Conv2d(1,20,5),
          nn.ReLU(),
          nn.Conv2d(20,64,5),
          nn.ReLU()
        )

# Using Sequential with OrderedDict. This is functionally the
# same as the above code
model = nn.Sequential(OrderedDict([
          ('conv1', nn.Conv2d(1,20,5)),
          ('relu1', nn.ReLU()),
          ('conv2', nn.Conv2d(20,64,5)),
          ('relu2', nn.ReLU())
        ]))</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MLSTM_FCNPlus" class="doc_header"><code>class</code> <code>MLSTM_FCNPlus</code><a href="https://github.com/timeseriesAI/tsai/tree/main/tsai/models/RNN_FCNPlus.py#L90" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MLSTM_FCNPlus</code>(<strong>*<code>args</code></strong>, <strong><code>se</code></strong>=<em><code>16</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>_RNN_FCN_BasePlus</code></p>
</blockquote>
<p>A sequential container.
Modules will be added to it in the order they are passed in the
constructor. Alternatively, an <code>OrderedDict</code> of modules can be
passed in. The <code>forward()</code> method of <code>Sequential</code> accepts any
input and forwards it to the first module it contains. It then
"chains" outputs to inputs sequentially for each subsequent module,
finally returning the output of the last module.</p>
<p>The value a <code>Sequential</code> provides over manually calling a sequence
of modules is that it allows treating the whole container as a
single module, such that performing a transformation on the
<code>Sequential</code> applies to each of the modules it stores (which are
each a registered submodule of the <code>Sequential</code>).</p>
<p>What's the difference between a <code>Sequential</code> and a
:class:<code>torch.nn.ModuleList</code>? A <code>ModuleList</code> is exactly what it
sounds like--a list for storing <code>Module</code> s! On the other hand,
the layers in a <code>Sequential</code> are connected in a cascading way.</p>
<p>Example::</p>

<pre><code># Using Sequential to create a small model. When `model` is run,
# input will first be passed to `Conv2d(1,20,5)`. The output of
# `Conv2d(1,20,5)` will be used as the input to the first
# `ReLU`; the output of the first `ReLU` will become the input
# for `Conv2d(20,64,5)`. Finally, the output of
# `Conv2d(20,64,5)` will be used as input to the second `ReLU`
model = nn.Sequential(
          nn.Conv2d(1,20,5),
          nn.ReLU(),
          nn.Conv2d(20,64,5),
          nn.ReLU()
        )

# Using Sequential with OrderedDict. This is functionally the
# same as the above code
model = nn.Sequential(OrderedDict([
          ('conv1', nn.Conv2d(1,20,5)),
          ('relu1', nn.ReLU()),
          ('conv2', nn.Conv2d(20,64,5)),
          ('relu2', nn.ReLU())
        ]))</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MGRU_FCNPlus" class="doc_header"><code>class</code> <code>MGRU_FCNPlus</code><a href="https://github.com/timeseriesAI/tsai/tree/main/tsai/models/RNN_FCNPlus.py#L95" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MGRU_FCNPlus</code>(<strong>*<code>args</code></strong>, <strong><code>se</code></strong>=<em><code>16</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>_RNN_FCN_BasePlus</code></p>
</blockquote>
<p>A sequential container.
Modules will be added to it in the order they are passed in the
constructor. Alternatively, an <code>OrderedDict</code> of modules can be
passed in. The <code>forward()</code> method of <code>Sequential</code> accepts any
input and forwards it to the first module it contains. It then
"chains" outputs to inputs sequentially for each subsequent module,
finally returning the output of the last module.</p>
<p>The value a <code>Sequential</code> provides over manually calling a sequence
of modules is that it allows treating the whole container as a
single module, such that performing a transformation on the
<code>Sequential</code> applies to each of the modules it stores (which are
each a registered submodule of the <code>Sequential</code>).</p>
<p>What's the difference between a <code>Sequential</code> and a
:class:<code>torch.nn.ModuleList</code>? A <code>ModuleList</code> is exactly what it
sounds like--a list for storing <code>Module</code> s! On the other hand,
the layers in a <code>Sequential</code> are connected in a cascading way.</p>
<p>Example::</p>

<pre><code># Using Sequential to create a small model. When `model` is run,
# input will first be passed to `Conv2d(1,20,5)`. The output of
# `Conv2d(1,20,5)` will be used as the input to the first
# `ReLU`; the output of the first `ReLU` will become the input
# for `Conv2d(20,64,5)`. Finally, the output of
# `Conv2d(20,64,5)` will be used as input to the second `ReLU`
model = nn.Sequential(
          nn.Conv2d(1,20,5),
          nn.ReLU(),
          nn.Conv2d(20,64,5),
          nn.ReLU()
        )

# Using Sequential with OrderedDict. This is functionally the
# same as the above code
model = nn.Sequential(OrderedDict([
          ('conv1', nn.Conv2d(1,20,5)),
          ('relu1', nn.ReLU()),
          ('conv2', nn.Conv2d(20,64,5)),
          ('relu2', nn.ReLU())
        ]))</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">tsai.models.utils</span> <span class="kn">import</span> <span class="n">count_parameters</span>
<span class="kn">from</span> <span class="nn">tsai.models.RNN_FCN</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">bs</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">n_vars</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">c_out</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">xb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">n_vars</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">RNN_FCNPlus</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">[</span><span class="n">bs</span><span class="p">,</span> <span class="n">c_out</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">LSTM_FCNPlus</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">[</span><span class="n">bs</span><span class="p">,</span> <span class="n">c_out</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">MLSTM_FCNPlus</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">[</span><span class="n">bs</span><span class="p">,</span> <span class="n">c_out</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">GRU_FCNPlus</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">[</span><span class="n">bs</span><span class="p">,</span> <span class="n">c_out</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">GRU_FCNPlus</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">[</span><span class="n">bs</span><span class="p">,</span> <span class="n">c_out</span><span class="p">])</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">count_parameters</span><span class="p">(</span><span class="n">LSTM_FCNPlus</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)),</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">LSTM_FCN</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">n_vars</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">c_out</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">xb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">n_vars</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span>
<span class="n">custom_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">228</span><span class="p">,</span> <span class="n">c_out</span><span class="p">)</span>
<span class="n">test_eq</span><span class="p">(</span><span class="n">RNN_FCNPlus</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">custom_head</span><span class="o">=</span><span class="n">custom_head</span><span class="p">)(</span><span class="n">xb</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">[</span><span class="n">bs</span><span class="p">,</span> <span class="n">c_out</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">LSTM_FCNPlus</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">c_out</span><span class="p">,</span> <span class="n">se</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>LSTM_FCNPlus(
  (backbone): _RNN_FCN_Base_Backbone(
    (rnn): LSTM(2, 100, batch_first=True)
    (rnn_dropout): Dropout(p=0.8, inplace=False)
    (convblock1): ConvBlock(
      (0): Conv1d(3, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (se1): SqueezeExciteBlock(
      (avg_pool): GAP1d(
        (gap): AdaptiveAvgPool1d(output_size=1)
        (flatten): Flatten(full=False)
      )
      (fc): Sequential(
        (0): Linear(in_features=128, out_features=16, bias=False)
        (1): ReLU()
        (2): Linear(in_features=16, out_features=128, bias=False)
        (3): Sigmoid()
      )
    )
    (convblock2): ConvBlock(
      (0): Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (se2): SqueezeExciteBlock(
      (avg_pool): GAP1d(
        (gap): AdaptiveAvgPool1d(output_size=1)
        (flatten): Flatten(full=False)
      )
      (fc): Sequential(
        (0): Linear(in_features=256, out_features=32, bias=False)
        (1): ReLU()
        (2): Linear(in_features=32, out_features=256, bias=False)
        (3): Sigmoid()
      )
    )
    (convblock3): ConvBlock(
      (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (gap): GAP1d(
      (gap): AdaptiveAvgPool1d(output_size=1)
      (flatten): Flatten(full=False)
    )
    (concat): Concat(dim=1)
  )
  (head): Sequential(
    (0): Linear(in_features=228, out_features=12, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

